#!/usr/bin/env python3
"""
é€šç”¨è‡¨ç•Œé›»æµåˆ†æå™¨
Universal Critical Current Analyzer

æ”¯æŒå¤šç¨®æ–‡ä»¶æ ¼å¼ï¼š
- {id}Ic.csv (æ¨™æº–è‡¨ç•Œé›»æµ)
- {id}Ic+.csv (æ­£å‘è‡¨ç•Œé›»æµ) 
- {id}Ic-.csv (è² å‘è‡¨ç•Œé›»æµ)

Author: GitHub Copilot
Date: 2025-06-02
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
import glob
import re
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import seaborn as sns

class UniversalIcAnalyzer:
    """é€šç”¨è‡¨ç•Œé›»æµåˆ†æå™¨"""
    
    def __init__(self, data_dir: str = "Ic"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_dir: æ•¸æ“šæ–‡ä»¶ç›®éŒ„è·¯å¾‘
        """
        self.data_dir = Path(data_dir)
        self.available_files = {}
        self.data_cache = {}
        
        # è¨­ç½®ç¹ªåœ–æ¨£å¼
        plt.style.use('default')
        sns.set_palette("husl")
        
        # æƒæå¯ç”¨æ–‡ä»¶
        self._scan_available_files()
    
    def _scan_available_files(self):
        """æƒæå¯ç”¨çš„ Ic æ–‡ä»¶"""
        if not self.data_dir.exists():
            print(f"âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {self.data_dir}")
            return
        
        # æ–‡ä»¶æ¨¡å¼
        patterns = {
            'standard': r'(\d+)Ic\.csv$',
            'positive': r'(\d+)Ic\+\.csv$', 
            'negative': r'(\d+)Ic-\.csv$',
            'special': r'([a-zA-Z]+\d+)Ic[+-]?\.csv$'  # æ”¯æŒ kay164Ic+.csv ç­‰ç‰¹æ®Šæ ¼å¼
        }
        
        for file_path in self.data_dir.glob("*.csv"):
            filename = file_path.name
            
            for file_type, pattern in patterns.items():
                match = re.search(pattern, filename)
                if match:
                    data_id = match.group(1)
                    
                    if data_id not in self.available_files:
                        self.available_files[data_id] = {}
                    
                    self.available_files[data_id][file_type] = file_path
                    break
        
        print(f"ğŸ” æƒæåˆ° {len(self.available_files)} å€‹æ•¸æ“šé›†:")
        for data_id in sorted(self.available_files.keys(), key=lambda x: (x.isdigit(), int(x) if x.isdigit() else x)):
            types = list(self.available_files[data_id].keys())
            print(f"  ğŸ“Š {data_id}: {', '.join(types)}")
    
    def get_available_ids(self) -> List[str]:
        """ç²å–æ‰€æœ‰å¯ç”¨çš„æ•¸æ“š ID"""
        return sorted(self.available_files.keys(), 
                     key=lambda x: (x.isdigit(), int(x) if x.isdigit() else x))
    
    def load_data(self, data_id: str, file_types: Optional[List[str]] = None) -> Dict[str, pd.DataFrame]:
        """
        è¼‰å…¥æŒ‡å®š ID çš„æ•¸æ“š
        
        Args:
            data_id: æ•¸æ“š ID
            file_types: è¦è¼‰å…¥çš„æ–‡ä»¶é¡å‹åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºè¼‰å…¥æ‰€æœ‰å¯ç”¨é¡å‹
            
        Returns:
            åŒ…å«ä¸åŒæ–‡ä»¶é¡å‹æ•¸æ“šçš„å­—å…¸
        """
        if data_id not in self.available_files:
            print(f"âŒ æ•¸æ“š ID '{data_id}' ä¸å­˜åœ¨")
            return {}
        
        if file_types is None:
            file_types = list(self.available_files[data_id].keys())
        
        loaded_data = {}
        
        for file_type in file_types:
            if file_type not in self.available_files[data_id]:
                print(f"âš ï¸  {data_id} æ²’æœ‰ {file_type} é¡å‹çš„æ–‡ä»¶")
                continue
            
            file_path = self.available_files[data_id][file_type]
            cache_key = f"{data_id}_{file_type}"
            
            # æª¢æŸ¥ç·©å­˜
            if cache_key in self.data_cache:
                loaded_data[file_type] = self.data_cache[cache_key]
                continue
            
            try:
                df = pd.read_csv(file_path)
                
                # é©—è­‰æ•¸æ“šæ ¼å¼
                if not self._validate_data_format(df):
                    print(f"âš ï¸  {file_path.name} æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º")
                    continue
                
                # æ•¸æ“šæ¸…ç†
                df = self._clean_data(df)
                
                # ç·©å­˜æ•¸æ“š
                self.data_cache[cache_key] = df
                loaded_data[file_type] = df
                
                print(f"âœ… è¼‰å…¥ {file_path.name}: {df.shape[0]} æ•¸æ“šé»")
                
            except Exception as e:
                print(f"âŒ è¼‰å…¥ {file_path.name} å¤±æ•—: {e}")
        
        return loaded_data
    
    def _validate_data_format(self, df: pd.DataFrame) -> bool:
        """é©—è­‰æ•¸æ“šæ ¼å¼"""
        required_columns = ['y_field', 'Ic']
        return all(col in df.columns for col in required_columns)
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†æ•¸æ“š"""
        # ç§»é™¤ NaN å€¼
        df = df.dropna()
        
        # æŒ‰ y_field æ’åº
        df = df.sort_values('y_field').reset_index(drop=True)
        
        # ç§»é™¤ç•°å¸¸å€¼ï¼ˆIc ç‚º 0 æˆ–è² å€¼ï¼‰
        df = df[df['Ic'] > 0]
        
        return df
    
    def plot_single_dataset(self, data_id: str, file_types: Optional[List[str]] = None, 
                           figsize: Tuple[int, int] = (12, 8), save_plot: bool = False) -> plt.Figure:
        """
        ç¹ªè£½å–®å€‹æ•¸æ“šé›†çš„åœ–è¡¨
        
        Args:
            data_id: æ•¸æ“š ID
            file_types: è¦ç¹ªè£½çš„æ–‡ä»¶é¡å‹åˆ—è¡¨
            figsize: åœ–è¡¨å¤§å°
            save_plot: æ˜¯å¦ä¿å­˜åœ–ç‰‡
            
        Returns:
            matplotlib Figure å°è±¡
        """
        data_dict = self.load_data(data_id, file_types)
        
        if not data_dict:
            print(f"âŒ ç„¡æ³•è¼‰å…¥æ•¸æ“šé›† {data_id}")
            return None
        
        fig, ax = plt.subplots(figsize=figsize)
        
        # é¡è‰²å’Œæ¨™è¨˜æ˜ å°„
        style_map = {
            'standard': {'color': 'blue', 'marker': 'o', 'label': 'Standard Ic'},
            'positive': {'color': 'red', 'marker': '^', 'label': 'Positive Ic'}, 
            'negative': {'color': 'green', 'marker': 'v', 'label': 'Negative Ic'},
            'special': {'color': 'purple', 'marker': 's', 'label': 'Special Ic'}
        }
        
        for file_type, df in data_dict.items():
            style = style_map.get(file_type, {'color': 'black', 'marker': 'o', 'label': file_type})
            
            # ç¢ºä¿æŒ‰ y_field æ’åºç¹ªè£½
            df_sorted = df.sort_values('y_field')
            
            ax.plot(df_sorted['y_field'], df_sorted['Ic'] * 1e6,  # è½‰æ›ç‚º ÂµA
                   color=style['color'], 
                   marker=style['marker'],
                   label=style['label'],
                   linewidth=2,
                   markersize=4,
                   alpha=0.8)
        
        # åœ–è¡¨è¨­ç½®
        ax.set_xlabel('Magnetic Field (y_field)', fontsize=12)
        ax.set_ylabel('Critical Current (ÂµA)', fontsize=12)
        ax.set_title(f'Critical Current vs Magnetic Field (Dataset {data_id})', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)
        
        # æ·»åŠ çµ±è¨ˆä¿¡æ¯
        self._add_statistics_text(ax, data_dict)
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡
        if save_plot:
            filename = f"ic_analysis_{data_id}.png"
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š åœ–ç‰‡å·²ä¿å­˜: {filename}")
        
        return fig
    
    def plot_comparison(self, data_ids: List[str], file_type: str = 'standard',
                       figsize: Tuple[int, int] = (16, 10), save_plot: bool = False) -> plt.Figure:
        """
        æ¯”è¼ƒå¤šå€‹æ•¸æ“šé›†
        
        Args:
            data_ids: è¦æ¯”è¼ƒçš„æ•¸æ“š ID åˆ—è¡¨
            file_type: æ–‡ä»¶é¡å‹
            figsize: åœ–è¡¨å¤§å°  
            save_plot: æ˜¯å¦ä¿å­˜åœ–ç‰‡
            
        Returns:
            matplotlib Figure å°è±¡
        """
        fig, ax = plt.subplots(figsize=figsize)
        
        colors = plt.cm.tab20(np.linspace(0, 1, len(data_ids)))
        
        valid_datasets = 0
        
        for i, data_id in enumerate(data_ids):
            data_dict = self.load_data(data_id, [file_type])
            
            if file_type not in data_dict:
                print(f"âš ï¸  æ•¸æ“šé›† {data_id} æ²’æœ‰ {file_type} é¡å‹æ–‡ä»¶")
                continue
            
            df = data_dict[file_type]
            df_sorted = df.sort_values('y_field')
            
            ax.plot(df_sorted['y_field'], df_sorted['Ic'] * 1e6,
                   color=colors[i],
                   label=f'Dataset {data_id}',
                   linewidth=2,
                   marker='o',
                   markersize=3,
                   alpha=0.8)
            
            valid_datasets += 1
        
        if valid_datasets == 0:
            print("âŒ æ²’æœ‰æœ‰æ•ˆçš„æ•¸æ“šé›†ç”¨æ–¼æ¯”è¼ƒ")
            return None
        
        # åœ–è¡¨è¨­ç½®
        ax.set_xlabel('Magnetic Field (y_field)', fontsize=12)
        ax.set_ylabel('Critical Current (ÂµA)', fontsize=12)
        ax.set_title(f'Critical Current Comparison ({file_type.title()})', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–ç‰‡
        if save_plot:
            filename = f"ic_comparison_{file_type}_{'_'.join(data_ids[:5])}.png"
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š æ¯”è¼ƒåœ–å·²ä¿å­˜: {filename}")
        
        return fig
    
    def _add_statistics_text(self, ax, data_dict: Dict[str, pd.DataFrame]):
        """æ·»åŠ çµ±è¨ˆä¿¡æ¯æ–‡æœ¬"""
        stats_text = []
        
        for file_type, df in data_dict.items():
            ic_values = df['Ic'] * 1e6  # ÂµA
            stats_text.append(f"{file_type.title()}:")
            stats_text.append(f"  Mean: {ic_values.mean():.2f} ÂµA")
            stats_text.append(f"  Max: {ic_values.max():.2f} ÂµA")
            stats_text.append(f"  Points: {len(ic_values)}")
            stats_text.append("")
        
        # æ·»åŠ æ–‡æœ¬æ¡†
        textstr = '\n'.join(stats_text[:-1])  # ç§»é™¤æœ€å¾Œçš„ç©ºè¡Œ
        props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
        ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=9,
               verticalalignment='top', bbox=props)
    
    def analyze_dataset(self, data_id: str) -> Dict:
        """
        åˆ†æå–®å€‹æ•¸æ“šé›†çš„è©³ç´°çµ±è¨ˆ
        
        Args:
            data_id: æ•¸æ“š ID
            
        Returns:
            åˆ†æçµæœå­—å…¸
        """
        data_dict = self.load_data(data_id)
        
        if not data_dict:
            return {}
        
        analysis = {
            'data_id': data_id,
            'available_types': list(data_dict.keys()),
            'statistics': {}
        }
        
        for file_type, df in data_dict.items():
            ic_values = df['Ic'] * 1e6  # ÂµA
            field_range = df['y_field'].max() - df['y_field'].min()
            
            stats = {
                'count': len(df),
                'mean_ic': ic_values.mean(),
                'std_ic': ic_values.std(),
                'max_ic': ic_values.max(),
                'min_ic': ic_values.min(),
                'field_range': field_range,
                'field_min': df['y_field'].min(),
                'field_max': df['y_field'].max()
            }
            
            analysis['statistics'][file_type] = stats
        
        return analysis
    
    def batch_analyze(self, data_ids: Optional[List[str]] = None, 
                     output_file: str = "ic_analysis_report.txt") -> Dict:
        """
        æ‰¹é‡åˆ†æå¤šå€‹æ•¸æ“šé›†
        
        Args:
            data_ids: è¦åˆ†æçš„æ•¸æ“š ID åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºåˆ†ææ‰€æœ‰
            output_file: å ±å‘Šè¼¸å‡ºæ–‡ä»¶å
            
        Returns:
            åˆ†æçµæœå­—å…¸
        """
        if data_ids is None:
            data_ids = self.get_available_ids()
        
        batch_results = {}
        
        print(f"ğŸ“Š é–‹å§‹æ‰¹é‡åˆ†æ {len(data_ids)} å€‹æ•¸æ“šé›†...")
        
        for data_id in data_ids:
            print(f"ğŸ“ˆ åˆ†ææ•¸æ“šé›† {data_id}...")
            analysis = self.analyze_dataset(data_id)
            if analysis:
                batch_results[data_id] = analysis
        
        # ç”Ÿæˆå ±å‘Š
        self._generate_analysis_report(batch_results, output_file)
        
        return batch_results
    
    def _generate_analysis_report(self, results: Dict, output_file: str):
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("è‡¨ç•Œé›»æµæ•¸æ“šåˆ†æå ±å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"åˆ†ææ™‚é–“: {pd.Timestamp.now()}\n")
            f.write(f"åˆ†ææ•¸æ“šé›†æ•¸é‡: {len(results)}\n\n")
            
            for data_id, analysis in results.items():
                f.write(f"æ•¸æ“šé›† ID: {data_id}\n")
                f.write("-" * 30 + "\n")
                f.write(f"å¯ç”¨æ–‡ä»¶é¡å‹: {', '.join(analysis['available_types'])}\n\n")
                
                for file_type, stats in analysis['statistics'].items():
                    f.write(f"  {file_type.title()} é¡å‹:\n")
                    f.write(f"    æ•¸æ“šé»æ•¸: {stats['count']}\n")
                    f.write(f"    å¹³å‡è‡¨ç•Œé›»æµ: {stats['mean_ic']:.3f} ÂµA\n")
                    f.write(f"    è‡¨ç•Œé›»æµæ¨™æº–å·®: {stats['std_ic']:.3f} ÂµA\n")
                    f.write(f"    æœ€å¤§è‡¨ç•Œé›»æµ: {stats['max_ic']:.3f} ÂµA\n")
                    f.write(f"    æœ€å°è‡¨ç•Œé›»æµ: {stats['min_ic']:.3f} ÂµA\n")
                    f.write(f"    ç£å ´ç¯„åœ: {stats['field_min']:.6f} - {stats['field_max']:.6f}\n")
                    f.write(f"    ç£å ´è·¨åº¦: {stats['field_range']:.6f}\n\n")
                
                f.write("\n")
        
        print(f"ğŸ“„ åˆ†æå ±å‘Šå·²ä¿å­˜: {output_file}")


# ä¾¿æ·å‡½æ•¸
def quick_plot(data_id: str, data_dir: str = "Ic", save_plot: bool = False):
    """å¿«é€Ÿç¹ªè£½å–®å€‹æ•¸æ“šé›†"""
    analyzer = UniversalIcAnalyzer(data_dir)
    fig = analyzer.plot_single_dataset(data_id, save_plot=save_plot)
    if fig:
        plt.show()
    return fig

def quick_compare(data_ids: List[str], file_type: str = 'standard', 
                 data_dir: str = "Ic", save_plot: bool = False):
    """å¿«é€Ÿæ¯”è¼ƒå¤šå€‹æ•¸æ“šé›†"""
    analyzer = UniversalIcAnalyzer(data_dir)
    fig = analyzer.plot_comparison(data_ids, file_type, save_plot=save_plot)
    if fig:
        plt.show()
    return fig


# ä¸»ç¨‹åºç¤ºä¾‹
if __name__ == "__main__":
    # å‰µå»ºåˆ†æå™¨
    analyzer = UniversalIcAnalyzer("Ic")
    
    # ç¤ºä¾‹ 1: åˆ†æå–®å€‹æ•¸æ“šé›† (åŸå§‹ä»£ç¢¼çš„æ”¹é€²ç‰ˆ)
    print("\nğŸ¯ ç¤ºä¾‹ 1: åˆ†ææ•¸æ“šé›† 93")
    fig1 = analyzer.plot_single_dataset("93", save_plot=True)
    if fig1:
        plt.show()
    
    # ç¤ºä¾‹ 2: æ¯”è¼ƒå¤šå€‹æ•¸æ“šé›†
    print("\nğŸ¯ ç¤ºä¾‹ 2: æ¯”è¼ƒæ•¸æ“šé›† 93, 164, 317, 500")
    compare_ids = ["93", "164", "317", "500"]
    fig2 = analyzer.plot_comparison(compare_ids, file_type='standard', save_plot=True)
    if fig2:
        plt.show()
    
    # ç¤ºä¾‹ 3: åˆ†ææ‰€æœ‰å¯ç”¨æ•¸æ“šé›†çš„çµ±è¨ˆä¿¡æ¯
    print("\nğŸ¯ ç¤ºä¾‹ 3: æ‰¹é‡çµ±è¨ˆåˆ†æ")
    # analyzer.batch_analyze()  # æ³¨é‡‹æ‰ä»¥é¿å…éé•·çš„åˆ†ææ™‚é–“
    
    # ç¤ºä¾‹ 4: å±•ç¤ºå…·æœ‰æ­£è² å‘æ•¸æ“šçš„æ•¸æ“šé›†
    print("\nğŸ¯ ç¤ºä¾‹ 4: å…·æœ‰æ­£è² å‘æ•¸æ“šçš„æ•¸æ“šé›†")
    bipolar_ids = []
    for data_id in analyzer.get_available_ids():
        files = analyzer.available_files[data_id]
        if 'positive' in files and 'negative' in files:
            bipolar_ids.append(data_id)
    
    print(f"ç™¼ç¾ {len(bipolar_ids)} å€‹å…·æœ‰æ­£è² å‘æ•¸æ“šçš„æ•¸æ“šé›†: {bipolar_ids[:10]}...")
    
    if bipolar_ids:
        # å±•ç¤ºç¬¬ä¸€å€‹é›™æ¥µæ€§æ•¸æ“šé›†
        sample_id = bipolar_ids[0]
        print(f"\nå±•ç¤ºé›™æ¥µæ€§æ•¸æ“šé›†: {sample_id}")
        fig3 = analyzer.plot_single_dataset(sample_id, ['positive', 'negative'], save_plot=True)
        if fig3:
            plt.show()
